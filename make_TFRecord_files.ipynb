{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3cf719f",
   "metadata": {
    "id": "b3cf719f"
   },
   "source": [
    "# MAKE  TFRECORD FILES\n",
    "Mathias Ramm Haugland // 28.01.22 // Master thesis // NTNU & OUH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90fa95f",
   "metadata": {
    "id": "f90fa95f"
   },
   "source": [
    "# For Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sdShGMHhFfvo",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sdShGMHhFfvo",
    "outputId": "4d6572a7-39e3-4b33-c4c4-ea1428ddba6e"
   },
   "outputs": [],
   "source": [
    "#For Colab\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72399a7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c72399a7",
    "outputId": "7eea0191-0a62-43a6-dc5e-20ddd6ebdb77"
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "# Clone the tensorflow models repository if it doesn't already exist\n",
    "if \"models\" in pathlib.Path.cwd().parts:\n",
    "    while \"models\" in pathlib.Path.cwd().parts:\n",
    "      os.chdir('..')\n",
    "elif not pathlib.Path('models').exists():\n",
    "    !git clone --depth 1 https://github.com/tensorflow/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9b720b",
   "metadata": {
    "id": "cc9b720b"
   },
   "outputs": [],
   "source": [
    "# Install the Object Detection API\n",
    "%%bash\n",
    "cd models/research/\n",
    "protoc object_detection/protos/*.proto --python_out=.\n",
    "cp object_detection/packages/tf2/setup.py .\n",
    "python -m pip install ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79fee12",
   "metadata": {
    "id": "e79fee12"
   },
   "outputs": [],
   "source": [
    "# For colab train/test images imported from drive\n",
    "!unzip 'drive/MyDrive/master/NBI_WLI.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "QrHTS6BZidZE",
   "metadata": {
    "id": "QrHTS6BZidZE"
   },
   "outputs": [],
   "source": [
    "!unzip 'drive/MyDrive/master/test_zip_json.zip'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rRxaJlzBKBU9",
   "metadata": {
    "id": "rRxaJlzBKBU9"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "HWBDwq82KElE",
   "metadata": {
    "id": "HWBDwq82KElE"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import argparse\n",
    "import xml.etree.ElementTree as ET\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edcf021c",
   "metadata": {
    "id": "edcf021c"
   },
   "source": [
    "# From Segmentation mask to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ca7526",
   "metadata": {
    "id": "60ca7526"
   },
   "outputs": [],
   "source": [
    "#Insert script here or make independently\n",
    "#additional script for doing this: mask_to_bbox.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e086934",
   "metadata": {
    "id": "8e086934"
   },
   "source": [
    "# From JSON to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5407a24d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 351
    },
    "id": "5407a24d",
    "outputId": "92362382-9ad5-4eb7-a3e1-9e20b675077d"
   },
   "outputs": [],
   "source": [
    "#inspired by https://github.com/nazililham11/detection_util_scripts/blob/master/generate_csv.py\n",
    "def __list_to_csv(annotations, output_file):\n",
    "    column_name = ['filename', 'width', 'height', 'class', 'xmin', 'ymin', 'xmax', 'ymax']\n",
    "    xml_df = pd.DataFrame(annotations, columns=column_name)\n",
    "    xml_df.to_csv(output_file, index=None)\n",
    "\n",
    "def json_to_csv(input_json, output_file ):\n",
    "    \"\"\"Reads a JSON file, generated by the VGG Image Annotator, and generates a single CSV file\"\"\"\n",
    "    with open(input_json) as f:\n",
    "        images = json.load(f)\n",
    "    \n",
    "    annotations = []\n",
    "    for entry in images:\n",
    "        filename = entry\n",
    "        #filename = entry.split(\".\")[0]+\"_SNBI.png\" # FOR SNBI \n",
    "        #HERE\n",
    "        width = images[entry][\"width\"]\n",
    "        height = images[entry][\"height\"]\n",
    "        for bbox in images[entry][\"bbox\"]:\n",
    "            c = bbox[\"label\"]\n",
    "            xmin = bbox[\"xmin\"]\n",
    "            ymin = bbox[\"ymin\"]\n",
    "            xmax = bbox[\"xmax\"]\n",
    "            ymax = bbox[\"ymax\"]\n",
    "\n",
    "            value = (filename, width, height, c, xmin, ymin, xmax, ymax)\n",
    "            annotations.append(value)\n",
    "    \n",
    "    __list_to_csv(annotations, output_file)\n",
    "\n",
    "#run\n",
    "json_to_csv('set3_det.json', 'set3_det.csv')\n",
    "json_to_csv('set3_class.json', 'set3_class.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8b0841",
   "metadata": {
    "id": "5a8b0841"
   },
   "source": [
    "# From CSV to TFRecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb0a32b",
   "metadata": {
    "id": "1eb0a32b"
   },
   "outputs": [],
   "source": [
    "#Inspired by https://github.com/douglasrizzo/detection_util_scripts/blob/master/generate_tfrecord.py\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import absolute_import\n",
    "\n",
    "import io\n",
    "import tensorflow as tf\n",
    "\n",
    "from PIL import Image\n",
    "from object_detection.utils import dataset_util\n",
    "from collections import namedtuple, OrderedDict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e26385",
   "metadata": {
    "id": "86e26385"
   },
   "outputs": [],
   "source": [
    "def __split(df, group):\n",
    "    data = namedtuple('data', ['filename', 'object'])\n",
    "    gb = df.groupby(group)\n",
    "    return [data(filename, gb.get_group(x)) for filename, x in zip(gb.groups.keys(), gb.groups)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b124390",
   "metadata": {
    "id": "4b124390"
   },
   "outputs": [],
   "source": [
    "\n",
    "def create_tf_example(group, path, class_dict):\n",
    "\n",
    "    with tf.io.gfile.GFile(os.path.join(path, '{}'.format(group.filename)), 'rb') as fid:\n",
    "        encoded_jpg = fid.read()\n",
    "    encoded_jpg_io = io.BytesIO(encoded_jpg)\n",
    "    image = Image.open(encoded_jpg_io)\n",
    "    width, height = image.size\n",
    "    \n",
    "    filename = group.filename.encode('utf8')\n",
    "    image_format = b'png' #IMPORTANT\n",
    "    xmins = []\n",
    "    xmaxs = []\n",
    "    ymins = []\n",
    "    ymaxs = []\n",
    "    classes_text = []\n",
    "    classes = []\n",
    "    weights = []\n",
    "    \n",
    "    for index, row in group.object.iterrows():\n",
    "        if set(['xmin_rel', 'xmax_rel', 'ymin_rel', 'ymax_rel']).issubset(set(row.index)):\n",
    "            xmin = row['xmin_rel']\n",
    "            xmax = row['xmax_rel']\n",
    "            ymin = row['ymin_rel']\n",
    "            ymax = row['ymax_rel']\n",
    "        \n",
    "        elif set(['xmin', 'xmax', 'ymin', 'ymax']).issubset(set(row.index)):\n",
    "            xmin = row['xmin'] / width\n",
    "            xmax = row['xmax'] / width\n",
    "            ymin = row['ymin'] / height\n",
    "            ymax = row['ymax'] / height\n",
    "        \n",
    "        xmins.append(xmin)\n",
    "        xmaxs.append(xmax)\n",
    "        ymins.append(ymin)\n",
    "        ymaxs.append(ymax)\n",
    "\n",
    "        if str(row['class']) == 'Hyper':\n",
    "          class_nam = 'Hyperplasia'\n",
    "        elif str(row['class']) == 'Adenoma':\n",
    "          class_nam = 'Adenoma'\n",
    "        else: print(\"WRONG Class NAME!\")\n",
    "\n",
    "        classes_text.append(class_nam.encode('utf8'))\n",
    "        classes.append(class_dict[class_nam])\n",
    "        \n",
    "        \"\"\"\n",
    "        #This didn't work\n",
    "        \n",
    "        if str(row['class']) == 'Adenoma':\n",
    "          weights.append(1.0)\n",
    "        else:\n",
    "          weights.append(1.0) #Hyperplasia or one-class polyp\n",
    "        \"\"\"\n",
    "    tf_example = tf.train.Example(features=tf.train.Features(\n",
    "        feature={\n",
    "            'image/height': dataset_util.int64_feature(height),\n",
    "            'image/width': dataset_util.int64_feature(width),\n",
    "            'image/filename': dataset_util.bytes_feature(filename),\n",
    "            'image/source_id': dataset_util.bytes_feature(filename),\n",
    "            'image/encoded': dataset_util.bytes_feature(encoded_jpg),\n",
    "            'image/format': dataset_util.bytes_feature(image_format),\n",
    "            'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
    "            'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
    "            'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
    "            'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
    "            'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
    "            'image/object/class/label': dataset_util.int64_list_feature(classes), \n",
    "#            'image/object/weight': dataset_util.float_list_feature(weights) # Important line\n",
    "}))\n",
    "    return tf_example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690a2468",
   "metadata": {
    "id": "690a2468"
   },
   "outputs": [],
   "source": [
    "def class_dict_from_pbtxt(pbtxt_path):\n",
    "    # open file, strip \\n, trim lines and keep only\n",
    "    # lines beginning with id or display_name\n",
    "    \n",
    "    with open(pbtxt_path, 'r', encoding='utf-8-sig') as f:\n",
    "        data = f.readlines()\n",
    "    \n",
    "    name_key = None\n",
    "    if any('display_name:' in s for s in data):\n",
    "        name_key = 'display_name:'\n",
    "    elif any('name:' in s for s in data):\n",
    "        name_key = 'name:'\n",
    "    \n",
    "    if name_key is None:\n",
    "        raise ValueError(\n",
    "            \"label map does not have class names, provided by values with the 'display_name' or 'name' keys in the contents of the file\"\n",
    "        )\n",
    "    data = [l.rstrip('\\n').strip() for l in data if 'id:' in l or name_key in l]\n",
    "    \n",
    "    ids = [int(l.replace('id:', '')) for l in data if l.startswith('id')]\n",
    "    names = [\n",
    "        l.replace(name_key, '').replace('\"', '').replace(\"'\", '').strip() for l in data\n",
    "        if l.startswith(name_key)]\n",
    "    \n",
    "    # join ids and display_names into a single dictionary\n",
    "    class_dict = {}\n",
    "    for i in range(len(ids)):\n",
    "        class_dict[names[i]] = ids[i]\n",
    "    return class_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8ed4e5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "0c8ed4e5",
    "outputId": "9d8f47db-b9ad-499b-cbad-5335f4560ff1"
   },
   "outputs": [],
   "source": [
    "#Fix names here\n",
    "#first detection, then class\n",
    "def rec(viddd,mode):\n",
    "  path2 = '/home/hemin/mathiasrammhaugland/master/final/' #SHIFT\n",
    "\n",
    "  pbtxt_input = path2+'label_map.pbtxt' #SHIFT\n",
    "  class_dict = class_dict_from_pbtxt(pbtxt_input)\n",
    "\n",
    "  output_path =  path2+viddd+'_piccolo_'+mode+'_4.record'\n",
    "  writer = tf.compat.v1.python_io.TFRecordWriter(output_path)\n",
    "\n",
    "  image_dir = path2+mode\n",
    "  path = os.path.join(image_dir)\n",
    "\n",
    "  csv_input = path2+'bbox.csv' #SHIFT\n",
    "  examples = pd.read_csv(csv_input)\n",
    "  grouped = __split(examples, 'filename')\n",
    "\n",
    "  for group in tqdm(grouped, desc='groups'):\n",
    "      tf_example = create_tf_example(group, path, class_dict)\n",
    "      writer.write(tf_example.SerializeToString())\n",
    "\n",
    "  writer.close()\n",
    "  output_path = os.path.join(os.getcwd(), output_path)\n",
    "  print('Successfully created the TFRecords: {}'.format(output_path))\n",
    "\n",
    "\n",
    "#run\n",
    "for mode in [\"snbi4\"]:\n",
    "  for viddd in [\"class\"]:\n",
    "    rec(viddd, mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_KoAaMM8x1Vs",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_KoAaMM8x1Vs",
    "outputId": "0d7dc955-ea3f-4695-da37-2e87e0545a04"
   },
   "outputs": [],
   "source": [
    "#compress for download\n",
    "!zip -r /content/recfiles.zip /content/recfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "EMWPOpDVKDz7",
   "metadata": {
    "id": "EMWPOpDVKDz7"
   },
   "outputs": [],
   "source": [
    "!rm -rf masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "taFpD3rP2sTc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "taFpD3rP2sTc",
    "outputId": "21d2193b-3cf0-418f-f47f-2be2b3032920"
   },
   "outputs": [],
   "source": [
    "shutil.move(\"/content/recfiles.zip\", \"/content/drive/MyDrive/master/recfiles.zip\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f1adcd",
   "metadata": {
    "id": "40f1adcd"
   },
   "source": [
    "# Check your TFRecord file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e17ac8",
   "metadata": {
    "id": "35e17ac8"
   },
   "outputs": [],
   "source": [
    "raw_dataset = tf.data.TFRecordDataset(\"train_piccolo_wlix.record\")\n",
    "a = []\n",
    "for raw_record in raw_dataset.take(1000):\n",
    "    example = tf.train.Example()\n",
    "    example.ParseFromString(raw_record.numpy())\n",
    "    a.append(example)\n",
    "print(a[21])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "X6JfxOxgZUux",
   "metadata": {
    "id": "X6JfxOxgZUux"
   },
   "outputs": [],
   "source": [
    "print(a[18\n",
    "        ])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "make_TFRecord_files.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
