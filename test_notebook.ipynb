{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use this Jupyter Notebook as a guide to run your trained model in inference mode\n",
    "\n",
    "created by Anton Morgunov\n",
    "\n",
    "inspired by [tensorflow object detection API tutorial](https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/training.html#exporting-a-trained-model)\n",
    "\n",
    "Modified by Mathias Ramm Haugland"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your first step is going to specify which unit you are going to work with for inference. Select between GPU or CPU and follow the below instructions for implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EVAL\n",
    "\n",
    "##### Run \"inference_as_raw_output\" on evaluation data\n",
    "##### Use result in \"pr_curve\" to make a pr_curve\n",
    "##### Choose a confidence threshold from the curve\n",
    "##### Use this as input to \"inference_with_plot\" along with test/eval data\n",
    "\n",
    "### TEST\n",
    "##### Run inference_as_raw_output on test data\n",
    "##### Use result in test_pr to get precision recall with conf thresh from eval\n",
    "##### Use this thresh as input to \"inference_with_plot\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os # importing OS in order to make GPU visible\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" # do not change anything in here\n",
    "\n",
    "# specify which device you want to work on.\n",
    "# Use \"-1\" to work on a CPU. Default value \"0\" stands for the 1st GPU that will be used\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" # TODO: specify your computational device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf # import tensorflow\n",
    "\n",
    "# checking that GPU is found\n",
    "if tf.test.gpu_device_name():\n",
    "    print('GPU found')\n",
    "else:\n",
    "    print(\"No GPU found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# other import\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next you will import import scripts that were already provided by Tensorflow API. **Make sure that Tensorflow is your current working directory.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys # importyng sys in order to access scripts located in a different folder\n",
    "\n",
    "path2scripts = '/home/hemin/mathiasrammhaugland/master/Tensorflow/models/research/'\n",
    "sys.path.insert(0, path2scripts) # making scripts in models/research available for import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing all scripts that will be needed to export your model and use it for inference\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.builders import model_builder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can import and build your trained model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: your current working directory should be Tensorflow.\n",
    "\n",
    "# TODO: specify two pathes: to the pipeline.config file and to the folder with trained model.\n",
    "path2config ='/home/hemin/mathiasrammhaugland/master/Tensorflow/workspace/exported_models/efficientdet_d0/classification_snbi4_4/pipeline.config'\n",
    "path2model = '/home/hemin/mathiasrammhaugland/master/Tensorflow/workspace/exported_models/efficientdet_d0/classification_snbi4_4/checkpoint/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not change anything in this cell\n",
    "configs = config_util.get_configs_from_pipeline_file(path2config) # importing config\n",
    "model_config = configs['model'] # recreating model config\n",
    "detection_model = model_builder.build(model_config=model_config, is_training=False) # importing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
    "ckpt.restore(os.path.join(path2model, 'ckpt-0')).expect_partial()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, path to label map should be provided. Category index will be created based on labal map file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path2label_map = '/home/hemin/mathiasrammhaugland/master/Tensorflow/workspace/data/classification/label_map.pbtxt' # TODO: provide a path to the label map file\n",
    "category_index = label_map_util.create_category_index_from_labelmap(path2label_map,use_display_name=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, a few supporting functions will be defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_fn(image):\n",
    "    \"\"\"\n",
    "    Detect objects in image.\n",
    "    \n",
    "    Args:\n",
    "      image: (tf.tensor): 4D input image\n",
    "      \n",
    "    Returs:\n",
    "      detections (dict): predictions that model made\n",
    "    \"\"\"\n",
    "\n",
    "    image, shapes = detection_model.preprocess(image)\n",
    "    prediction_dict = detection_model.predict(image, shapes)\n",
    "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
    "\n",
    "    return detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_into_numpy_array(path):\n",
    "    \"\"\"Load an image from file into a numpy array.\n",
    "\n",
    "    Puts image into numpy array to feed into tensorflow graph.\n",
    "    Note that by convention we put it into a numpy array with shape\n",
    "    (height, width, channels), where channels=3 for RGB.\n",
    "\n",
    "    Args:\n",
    "      path: the file path to the image\n",
    "\n",
    "    Returns:\n",
    "      numpy array with shape (img_height, img_width, 3)\n",
    "    \"\"\"\n",
    "    \n",
    "    return np.array(Image.open(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def make_gt_im(im_np,gt_dic,cat_idx):\n",
    "    height = int(gt_dic['height'])\n",
    "    width = int(gt_dic['width'])\n",
    "    \n",
    "    boxes = []\n",
    "    classes = []\n",
    "    scores = []\n",
    "    if height != im_np.shape[0] or width != im_np.shape[1]:\n",
    "        print(\"BBox hasnt same dimensions as image!\")\n",
    "    else:\n",
    "        for box in gt_dic['bbox']:\n",
    "            coordinates = [int(box['ymin'])/height,int(box['xmin'])/width,int(box['ymax'])/height,int(box['xmax'])/width]\n",
    "            boxes.append(coordinates)\n",
    "            \n",
    "            if (box['label'] == 'polyp'):\n",
    "                classes.append(1)\n",
    "            if (box['label'] == 'Hyperplasia'):\n",
    "                classes.append(1)\n",
    "            elif (box['label'] == 'Adenoma'):\n",
    "                classes.append(2)\n",
    "                \n",
    "            scores.append(1)\n",
    "        boxes = np.array(boxes)\n",
    "        viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "                im_np,\n",
    "                boxes,\n",
    "                classes,\n",
    "                scores,\n",
    "                cat_idx,\n",
    "                use_normalized_coordinates=True,\n",
    "                max_boxes_to_draw=100,\n",
    "                min_score_thresh=0.0,\n",
    "                agnostic_mode=False,\n",
    "                line_thickness=4)\n",
    "        \n",
    "        return im_np\n",
    "    #return im_np_with_gt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Next function is the one that you can use to run inference and plot results an an input image:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def inference_with_plot(path2images, outpath, box_th=0.05, gt_json = None, nms_th=0.2):\n",
    "    \"\"\"\n",
    "    Function that performs inference and plots resulting b-boxes\n",
    "    \n",
    "    Args:\n",
    "      path2images: an array with pathes to images\n",
    "      box_th: (float) value that defines threshold for model prediction.\n",
    "      gt_json: json file with gt_boxes to be plotted on the same image.\n",
    "      \n",
    "    Returns:\n",
    "      None\n",
    "    \"\"\"\n",
    "    \n",
    "    if gt_json:\n",
    "        f = open(gt_json)\n",
    "        gt_dic = json.load(f)\n",
    "    \n",
    "    i=0\n",
    "    for image_path in path2images:\n",
    "        \n",
    "        print('Running inference for {}... '.format(image_path), end='')\n",
    "        \n",
    "        im_name = image_path.split('/')[-1].replace('jpg','jpg')\n",
    "        image_np = load_image_into_numpy_array(image_path)\n",
    "\n",
    "        input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "        detections = detect_fn(input_tensor)\n",
    "        # All outputs are batches tensors.\n",
    "        # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n",
    "        # We're only interested in the first num_detections.\n",
    "        num_detections = int(detections.pop('num_detections'))\n",
    "        detections = {key: value[0, :num_detections].numpy()\n",
    "                      for key, value in detections.items()}\n",
    "        \n",
    "        detections['num_detections'] = num_detections\n",
    "\n",
    "        # detection_classes should be ints.\n",
    "        detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "        label_id_offset = 1\n",
    "        image_np_with_detections = image_np.copy()\n",
    "        \n",
    "        \n",
    "        if nms_th: # filtering rectangles if nms threshold was passed in as a parameter\n",
    "        # creating a zip object that will contain model output info as\n",
    "            output_info = list(zip(detections['detection_boxes'],\n",
    "                                    detections['detection_scores'],\n",
    "                                    detections['detection_classes']\n",
    "                                        )\n",
    "                                )\n",
    "            #print(nms_th)\n",
    "            boxes, scores, classes = nms(output_info, thd = nms_th)\n",
    "        \n",
    "        boxes = np.array(boxes)\n",
    "        scores = np.array(scores)\n",
    "        classes = np.array(classes)\n",
    "        viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "                image_np_with_detections,\n",
    "                boxes,\n",
    "                classes+label_id_offset,\n",
    "                scores,\n",
    "                category_index,\n",
    "                use_normalized_coordinates=True,\n",
    "                max_boxes_to_draw=6,\n",
    "                min_score_thresh=box_th,\n",
    "                agnostic_mode=False,\n",
    "                line_thickness=4)\n",
    "        if gt_json:\n",
    "            image_np_with_gt = make_gt_im(image_np.copy(),gt_dic[im_name],category_index)\n",
    "            im_comb = np.hstack([image_np_with_detections,image_np_with_gt])\n",
    "            image_np_with_detections = im_comb\n",
    "        plt.figure(figsize=(15,10))\n",
    "        plt.imshow(image_np_with_detections)\n",
    "        plt.savefig(outpath+im_name)\n",
    "        i+=1\n",
    "        print('Done')\n",
    "    #plt.show()\n",
    "    if gt_json:\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print images with detection vs bboxes:\n",
    "#get test images on array format2\n",
    "t = 'test'\n",
    "v= 'v24'\n",
    "path = '/home/hemin/mathiasrammhaugland/master/set3/SNBI4/images_snbi4/' #eval or test\n",
    "image_path_array = []\n",
    "for file_name in os.listdir(path):\n",
    "    image_path_array.append(path+file_name)\n",
    "\n",
    "\n",
    "inference_with_plot(image_path_array,\n",
    "                    outpath = f\"./{t}_results_images/classification_snbi4_4/\", #test or eval data?\n",
    "                    box_th = 0.22,\n",
    "                    gt_json = f'/home/hemin/mathiasrammhaugland/master/set3/set3_class.json',#WLI normally\n",
    "                    nms_th=0.2\n",
    "                   )\n",
    "                 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will define a few other supporting functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nms(rects, thd=0.2):\n",
    "    \"\"\"\n",
    "    Filter rectangles\n",
    "    rects is array of oblects ([x1,y1,x2,y2], confidence, class)\n",
    "    thd - intersection threshold (intersection divides min square of rectange)\n",
    "    \"\"\"\n",
    "    out = []\n",
    "\n",
    "    remove = [False] * len(rects)\n",
    "\n",
    "    for i in range(0, len(rects) - 1):\n",
    "        if remove[i]:\n",
    "            continue\n",
    "        inter = [0.0] * len(rects)\n",
    "        for j in range(i, len(rects)):\n",
    "            if remove[j]:\n",
    "                continue\n",
    "            inter[j] = intersection(rects[i][0], rects[j][0]) / min(square(rects[i][0]), square(rects[j][0]))\n",
    "\n",
    "        max_prob = 0.0\n",
    "        max_idx = 0\n",
    "        for k in range(i, len(rects)):\n",
    "            if inter[k] >= thd:\n",
    "                if rects[k][1] > max_prob:\n",
    "                    max_prob = rects[k][1]\n",
    "                    max_idx = k\n",
    "\n",
    "        for k in range(i, len(rects)):\n",
    "            if (inter[k] >= thd) & (k != max_idx):\n",
    "                remove[k] = True\n",
    "\n",
    "    for k in range(0, len(rects)):\n",
    "        if not remove[k]:\n",
    "            out.append(rects[k])\n",
    "\n",
    "    boxes = [box[0] for box in out]\n",
    "    scores = [score[1] for score in out]\n",
    "    classes = [cls[2] for cls in out]\n",
    "    return boxes, scores, classes\n",
    "\n",
    "\n",
    "def intersection(rect1, rect2):\n",
    "    \"\"\"\n",
    "    Calculates square of intersection of two rectangles\n",
    "    rect: list with coords of top-right and left-boom corners [x1,y1,x2,y2]\n",
    "    return: square of intersection\n",
    "    \"\"\"\n",
    "    x_overlap = max(0, min(rect1[2], rect2[2]) - max(rect1[0], rect2[0]));\n",
    "    y_overlap = max(0, min(rect1[3], rect2[3]) - max(rect1[1], rect2[1]));\n",
    "    overlapArea = x_overlap * y_overlap;\n",
    "    return overlapArea\n",
    "\n",
    "\n",
    "def square(rect):\n",
    "    \"\"\"\n",
    "    Calculates square of rectangle\n",
    "    \"\"\"\n",
    "    return abs(rect[2] - rect[0]) * abs(rect[3] - rect[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Next function is the one that you can use to run inference and save results into a file:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_as_raw_output(path2images,\n",
    "                            box_th = 0.0,\n",
    "                            nms_th = 0.2,\n",
    "                            to_file = False,\n",
    "                            data = None,\n",
    "                            path2dir = True):\n",
    "    \"\"\"\n",
    "    Function that performs inference and return filtered predictions\n",
    "    \n",
    "    Args:\n",
    "      path2images: an array with pathes to images\n",
    "      box_th: (float) value that defines threshold for model prediction. Consider 0.25 as a value.\n",
    "      nms_th: (float) value that defines threshold for non-maximum suppression. Consider 0.5 as a value.\n",
    "      to_file: (boolean). When passed as True => results are saved into a file. Writing format is\n",
    "      path2image + (x1abs, y1abs, x2abs, y2abs, score, conf) for box in boxes\n",
    "      data: (str) name of the dataset you passed in (e.g. test/validation)\n",
    "      path2dir: (str). Should be passed if path2images has only basenames. If full pathes provided => set False.\n",
    "      \n",
    "    Returs:\n",
    "      detections (dict): filtered predicclassificationtions that model made\n",
    "    \"\"\"\n",
    "        \n",
    "    print (f'Current data set is {data}')\n",
    "    print (f'Ready to start inference on {len(path2images)} images!')\n",
    "    \n",
    "    for image_path in tqdm(os.listdir(path2images)):\n",
    "        #print(image_path)\n",
    "        if path2dir: # if a path to a directory where images are stored was passed in\n",
    "            image_path = os.path.join(path2images, image_path.strip())\n",
    "\n",
    "        image_np = load_image_into_numpy_array(image_path)\n",
    "\n",
    "        input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "        detections = detect_fn(input_tensor)\n",
    "        \n",
    "        # checking how many detections we got\n",
    "        num_detections = int(detections.pop('num_detections'))\n",
    "        \n",
    "        # filtering out detection in order to get only the one that are indeed detections\n",
    "        detections = {key: value[0, :num_detections].numpy() for key, value in detections.items()}\n",
    "        \n",
    "        # detection_classes should be ints.\n",
    "        detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "        \n",
    "        # defining what we need from the resulting detection dict that we got from model output\n",
    "        key_of_interest = ['detection_classes', 'detection_boxes', 'detection_scores']\n",
    "        \n",
    "        # filtering out detection dict in order to get only boxes, classes and scores\n",
    "        detections = {key: value for key, value in detections.items() if key in key_of_interest}\n",
    "        \n",
    "        if box_th: # filtering detection if a confidence threshold for boxes was given as a parameter\n",
    "            for key in key_of_interest:\n",
    "                scores = detections['detection_scores']\n",
    "                current_array = detections[key]\n",
    "                filtered_current_array = current_array[scores > box_th]\n",
    "                detections[key] = filtered_current_array\n",
    "        \n",
    "        if nms_th: # filtering rectangles if nms threshold was passed in as a parameter\n",
    "            # creating a zip object that will contain model output info as\n",
    "            output_info = list(zip(detections['detection_boxes'],\n",
    "                                   detections['detection_scores'],\n",
    "                                   detections['detection_classes']\n",
    "                                  )\n",
    "                              )\n",
    "            boxes, scores, classes = nms(output_info)\n",
    "            \n",
    "            detections['detection_boxes'] = boxes # format: [y1, x1, y2, x2]\n",
    "            detections['detection_scores'] = scores\n",
    "            detections['detection_classes'] = classes\n",
    "\n",
    "        #print(detections)\n",
    "\n",
    "        if to_file and data: # if saving to txt file was requested\n",
    "\n",
    "            image_h, image_w, _ = image_np.shape\n",
    "            file_name = f'{data}_results.txt'\n",
    "            \n",
    "            line2write = list()\n",
    "            line2write.append(os.path.basename(image_path))\n",
    "            \n",
    "            with open(file_name, 'a+') as text_file:\n",
    "                # iterating over boxes\n",
    "                for b, s, c in zip(boxes, scores, classes):\n",
    "                    \n",
    "                    y1abs, x1abs = b[0] * image_h, b[1] * image_w\n",
    "                    y2abs, x2abs = b[2] * image_h, b[3] * image_w\n",
    "                    \n",
    "                    list2append = [x1abs, y1abs, x2abs, y2abs, s, c]\n",
    "                    line2append = ','.join([str(item) for item in list2append])\n",
    "                    \n",
    "                    line2write.append(line2append)\n",
    "                \n",
    "                line2write = ' '.join(line2write)\n",
    "                text_file.write(line2write + os.linesep)\n",
    "    return detections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the inference_as_raw_output function to get these x and y coordinates (and classification), and compare these with values from a json file of the test data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test function to write each video to a txt file\n",
    "#test_folders=\"/media/hemin/Data/Hemin'sFiles/My_Dataset/OUS-NBI-ColonVDB-master/test/WLI/polyps/\" #WLI or 'NBI/'\n",
    "t= \"eval\"\n",
    "\n",
    "test_folders=\"/home/hemin/mathiasrammhaugland/master/set2/SNBI4/\"+t #SNBI \"test/all or eval\"\n",
    "\n",
    "#For multiple test folders:\n",
    "#for folder in os.listdir(test_folders):\n",
    "#    inference_as_raw_output(test_folders+'/'+folder+\"/\", to_file=True, data=\"test_results/detection_wli_1/\"+folder+\"_wli\")\n",
    "\n",
    "#Only one test folder:\n",
    "#inference_as_raw_output(test_folders, to_file=True, data='test_results/classification_snbi4_4/class_snbi4_'+t)\n",
    "\n",
    "#ex3\n",
    "inference_as_raw_output(\"/home/hemin/mathiasrammhaugland/master/set3/SNBI4/Adenoma\", \n",
    "                        to_file=True,\n",
    "                        data='test_results/classification_snbi4_4/class_snbi4_test_kumc_adenoma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "#calculate IoU between one gt and one pred box, given a confidence threshold:\n",
    "def calc_iou(pred_box,gt_box,im_h,im_w):\n",
    "    empty = np.zeros(int(im_h)*int(im_w)).reshape([int(im_h),int(im_w)])\n",
    "    actual = empty.copy()\n",
    "\n",
    "    actual = cv2.rectangle(actual,[gt_box[0],gt_box[1]],[gt_box[2],gt_box[3]],1,-1)\n",
    "    \n",
    "    pred = empty.copy()\n",
    "    \n",
    "    pred = cv2.rectangle(pred,[pred_box[0],pred_box[1]],[pred_box[2],pred_box[3]],2,-1)\n",
    "\n",
    "    combined = np.squeeze(np.asarray(np.add(pred, actual)))\n",
    "    unique, counts = np.unique(combined, return_counts=True) #unique=index, counts=#\n",
    "\n",
    "    zipped = dict(zip(unique,counts))\n",
    "\n",
    "    for un in [1.0,2.0,3.0]:\n",
    "        if un not in zipped:\n",
    "            zipped[un] = 0.0\n",
    "            \n",
    "            \n",
    "    \n",
    "            \n",
    "    #0.0 = true negative\n",
    "    #1.0 = false negative\n",
    "    #2.0 = false positive\n",
    "    #3.0 = true positive/intersection\n",
    "    #union = 1+2+3\n",
    "\n",
    "    intersection = zipped.get(3.0)\n",
    "\n",
    "    union = zipped.get(1.0) + zipped.get(2.0) + zipped.get(3.0)\n",
    "\n",
    "    iou_i = intersection/union\n",
    "    #print(iou_i)\n",
    "    return iou_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_and_neg_pr_im(pred_mat, gt_mat, im_h, im_w, thresh, gt_class, pred_class_scores,iou_th=0.2):\n",
    "    tp = 0\n",
    "    tp_fp = 0\n",
    "    tp_fn = 0    \n",
    "\n",
    "    i = 0\n",
    "\n",
    "    for pred_box in pred_mat:\n",
    "        conf_score = pred_class_scores[i][1]\n",
    "        class_pred = pred_class_scores[i][0]\n",
    "        iou_j = -1 #the highest iou\n",
    "        if conf_score >= thresh:\n",
    "            for gt_box in gt_mat:\n",
    "                class_gt = gt_class[0]\n",
    "                iou_i = calc_iou(pred_box,gt_box,im_h,im_w)\n",
    "\n",
    "\n",
    "                if iou_i > iou_j:\n",
    "                    if class_pred == class_gt:\n",
    "                        iou_j = iou_i\n",
    "                            \n",
    "            tp_fp = tp_fp+1\n",
    "            if iou_j>=iou_th: #our IOU threshold\n",
    "                tp = tp+1\n",
    "        i = i+1\n",
    "                    \n",
    "    \n",
    "    tp_fn = tp_fn + len(gt_mat)\n",
    "    \n",
    "    \n",
    "    return tp,tp_fp, tp_fn\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#different metrics\n",
    "def metrics(pred_lst, gt_lst, gt_class_lst, pred_class_score_lst, h_lst, w_lst, iou_th = 0.2, thresh = 0.2):\n",
    "    #get pr and rc\n",
    "    tp_sum = 0\n",
    "    tp_fp_sum = 0\n",
    "    tp_fn_sum = 0\n",
    "    \n",
    "    for i in range(len(pred_lst)):\n",
    "        tp, tp_fp, tp_fn = pos_and_neg_pr_im(pred_lst[i],\n",
    "                                             gt_lst[i],\n",
    "                                             h_lst[i],\n",
    "                                             w_lst[i],\n",
    "                                             thresh, \n",
    "                                             gt_class_lst[i],\n",
    "                                             pred_class_score_lst[i],\n",
    "                                             iou_th)\n",
    "        tp_sum += tp\n",
    "        tp_fp_sum += tp_fp\n",
    "        tp_fn_sum += tp_fn\n",
    "\n",
    "\n",
    "    print(\"Conf Thresh: {}\".format(thresh))\n",
    "    print(\"TPs: {}\".format(tp_sum))\n",
    "    print(\"TPFPs: {}\".format(tp_fp_sum))\n",
    "    print(\"TPFNs: {}\".format(tp_fn_sum))\n",
    "    \n",
    "    if tp_fp_sum == 0:\n",
    "        precision = 1\n",
    "        recall = tp_sum/tp_fn_sum\n",
    "    elif tp_fn_sum == 0:\n",
    "        precision = tp_sum/tp_fp_sum\n",
    "        recall = 1\n",
    "    else:\n",
    "        precision = tp_sum/(tp_fp_sum)\n",
    "        recall = tp_sum/(tp_fn_sum)\n",
    "    print(\"Prec: {}\".format(precision))\n",
    "    print(\"Recall: {}\".format(recall))\n",
    "    return precision, recall, tp_sum,tp_fp_sum, tp_fn_sum\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "#FOR CALCULATING PR CURVE OF EVALUATION DATA TO FIND BEST CONF THRESHOLD\n",
    "\n",
    "t = 'test'\n",
    "mo = 'snbi4'\n",
    "\n",
    "def data_prep(vvv=None):\n",
    "    #gt_file = f'/home/hemin/mathiasrammhaugland/master/set2/gt_boxes/class_{t}_piccolo_wli.json' #wli or nbi\n",
    "    gt_file = '/home/hemin/mathiasrammhaugland/master/set3/set3_class.json'\n",
    "    json_file = open(gt_file)\n",
    "    gt = json.load(json_file)\n",
    "    #pred_file = open(f'./test_results/classification_{mo}_4/class_{mo}_{t}_results.txt','r') #only \"wli\" here when testin wli\n",
    "    pred_file = open(f'./test_results/classification_{mo}_4/class_{mo}_{t}_kumc_all_results.txt','r')\n",
    "    gt_lst= [] #list of all bboxes from one video.\n",
    "    pred_lst = [] #list of all prediction bboxes from the same video.\n",
    "    w_lst, h_lst = [],[] #list of image heights and widths\n",
    "    pred_class_and_score_lst = []\n",
    "    gt_class_lst = []\n",
    "    gt_count = 0\n",
    "    for line in pred_file:\n",
    "        \n",
    "        l= line.split(' ')\n",
    "            \n",
    "        l[-1] = l[-1].strip('\\n')\n",
    "\n",
    "        name = l.pop(0)#filename\n",
    "\n",
    "        #get prediction on correct format (list of lists)\n",
    "        pred_mat=[]\n",
    "        pred_class_and_score =[]\n",
    "        \n",
    "        if (name.split('_')[0] == vvv or vvv == None):\n",
    "            for pred in l:\n",
    "                p=pred.split(',')\n",
    "                p_w = []\n",
    "                c=0\n",
    "                while(c<4):\n",
    "                    p_w.append(int(round(float(p[c]))))\n",
    "                    c+=1\n",
    "                pred_mat.append(p_w)\n",
    "        \n",
    "                pc = [int(p[-1]),float(p[-2])] #class and conf score\n",
    "                pred_class_and_score.append(pc)\n",
    "\n",
    "                #get corresponding gt from filename\n",
    "            #print(gt)\n",
    "            gt_i = gt.get(name.replace('png','jpg')) #CHECK\n",
    "                #get gt on list of lists format\n",
    "            #print(gt_i)\n",
    "            gt_mat=[]\n",
    "            gt_class = []\n",
    "            for el in gt_i['bbox']:\n",
    "                gt_mat.append([int(el['xmin']),int(el['ymin']),int(el['xmax']),int(el['ymax'])]) #here is also label possible to acquire as el['label']\n",
    "                if el['label'] == 'polyp':\n",
    "                    gt_class.append(0)\n",
    "                if el['label'] == 'Hyperplasia':\n",
    "                    gt_class.append(0)\n",
    "                elif el['label'] == 'Adenoma':\n",
    "                    gt_class.append(1)\n",
    "                gt_count = gt_count+1\n",
    "\n",
    "            if (gt_mat != []) and (pred_mat != []): #If either the gt or the prediction contains bbox(es)\n",
    "                    h_lst.append(int(gt_i['height']))\n",
    "                    w_lst.append(int(gt_i['width']))\n",
    "                    gt_lst.append(gt_mat)\n",
    "                    gt_class_lst.append(gt_class)\n",
    "                    pred_lst.append(pred_mat)\n",
    "                    pred_class_and_score_lst.append(pred_class_and_score)\n",
    "\n",
    "    return pred_lst,gt_lst,gt_class_lst,pred_class_and_score_lst,h_lst,w_lst\n",
    "                \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def pr_curve():\n",
    "    pred_lst,gt_lst,gt_class_lst,pred_class_and_score_lst,h_lst,w_lst = data_prep()\n",
    "    iou_th = 0.5 #ex\n",
    "    prec = []\n",
    "    rec = []\n",
    "    #print(\"GT amount: {}\".format(gt_count))\n",
    "    for conf_thresh in range(0,100,1):\n",
    "        prec_i,rec_i,_,tp_fp_sum,tp_fn_sum = metrics(pred_lst,\n",
    "                                                     gt_lst,\n",
    "                                                     gt_class_lst,\n",
    "                                                     pred_class_and_score_lst,\n",
    "                                                     h_lst,\n",
    "                                                     w_lst,\n",
    "                                                     iou_th = iou_th,\n",
    "                                                     thresh = conf_thresh/100)\n",
    "        prec.append(prec_i)\n",
    "        rec.append(rec_i)\n",
    "        if conf_thresh % 10 == 0: \n",
    "            print(conf_thresh)\n",
    "\n",
    "    return prec, rec\n",
    "\n",
    "prec, rec = pr_curve() #takes some time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FOR TESTING\n",
    "def test_pr():\n",
    "    iou=0.5        \n",
    "    ct = 0.22\n",
    "    f1_lst = []\n",
    "    for vvv in [None]:\n",
    "    #for vvv in [None,'v1','v2','v3','v4','v5','v7','v8','v9','v10','v12','v13','v14','v15','v16','v18','v20','v24']:\n",
    "        pred_lst,gt_lst,gt_class_lst,pred_class_and_score_lst,h_lst,w_lst = data_prep(vvv)\n",
    "        prec,rec,_,_,_ = metrics(pred_lst,\n",
    "                            gt_lst,\n",
    "                            gt_class_lst,\n",
    "                            pred_class_and_score_lst,\n",
    "                            h_lst,\n",
    "                            w_lst,\n",
    "                            iou_th = iou,\n",
    "                            thresh = ct)\n",
    "        f1 = 2*prec*rec/(prec+rec+1e-16)\n",
    "                \n",
    "        print(f\"For {vvv}, an IOUth of {iou} and conf thresh of {ct} gives f1: {f1} and precision/recall: {prec}/{rec}\")\n",
    "            \n",
    "test_pr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "val = 22\n",
    "plt.plot(rec,prec)\n",
    "plt.plot(rec[val],prec[val], marker=\"o\", markeredgecolor=\"red\")\n",
    "plt.annotate(\"Threshold = {}\".format(val/100), (rec[val],prec[val]),color = \"red\")\n",
    "#plt.annotate(\"Recall = {}\".format(rec[val]), (max(rec)/2, max(prec)/2),color = \"red\")\n",
    "#plt.annotate(\"Precision = {}\".format(prec[val]), (max(rec)/3, max(prec)/3),color = \"red\")\n",
    "plt.title(\"SNBI4 classification validation PR-Curve @.5\")\n",
    "plt.xlabel(\"Recall ({})\".format(round(rec[val],3)))\n",
    "plt.ylabel(\"Precision ({})\".format(round(prec[val],3)))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "f1 =[]\n",
    "iss = []\n",
    "for i in range(len(rec)):\n",
    "    iss.append(i)\n",
    "    f1.append(2*rec[i]*prec[i]/(rec[i]+prec[i]))\n",
    "\n",
    "plt.plot(iss,f1)\n",
    "plt.plot(iss[val],f1[val], marker=\"o\", markeredgecolor=\"red\")\n",
    "plt.annotate(\"Threshold = {}\".format(val/100), (iss[val],f1[val]),color = \"red\")\n",
    "plt.title(\"SNBI4 classification validation F1 curve @.5\")\n",
    "plt.xlabel(\"Confidence threshold\")\n",
    "plt.ylabel(\"F1-score ({})\".format(round(f1[val],3)))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "prec2 = prec\n",
    "prec2[0] = 0\n",
    "rec2 = rec\n",
    "rec2[-1] = 0\n",
    "\n",
    "print(f\"AUC of PR-curve: {auc(rec2,prec2)}\") #yeah??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "neptune": {
   "notebookId": "7c618cd5-39ec-46c6-bee7-0cfe5297f22a"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
